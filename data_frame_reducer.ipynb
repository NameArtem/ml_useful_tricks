{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T11:28:01.377950Z",
     "start_time": "2019-04-19T11:28:00.713840Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T11:29:29.536329Z",
     "start_time": "2019-04-19T11:29:29.364924Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reducer could readuce your Pandas DataFrame\n",
    "\n",
    "This process doesn't change data into a DataFrame,\n",
    "it only replaces datatypes and sets necessary datatypes for each columns\n",
    "\"\"\"\n",
    "\n",
    "def mem_usage(obj):\n",
    "    \"\"\"\n",
    "    Function chech current size of a DataFrame\n",
    "    \n",
    "    input: pd.DataFrame | pd.Series\n",
    "    \n",
    "    return: sting\n",
    "    \"\"\"\n",
    "    #if DataFrame\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        usage_b = obj.memory_usage(deep = True).sum()\n",
    "    #if Series\n",
    "    else:\n",
    "        usage_b = obj.memory_usage(deep = True)\n",
    "    usage_mb = usage_b / 1024 ** 2 # convert bytes to megabytes\n",
    "    return \"{:03.2f} MB\".format(usage_mb)\n",
    "\n",
    "\n",
    "\n",
    "def replace_cat(obj, min_value=0.10, features=None):\n",
    "    \"\"\"\n",
    "    Function converts objects to numveric types\n",
    "    (only columns which are less unique then min_value % is)\n",
    "    \n",
    "    input: pd.DataFrame | pd.Series\n",
    "    input: hasattr(features, '__iter__')\n",
    "    input: .0 =< min_value >= 1.\n",
    "    \n",
    "    return pd.DataFrame | pd.Series\n",
    "    \"\"\"\n",
    "    #it's only with DataFrame\n",
    "    if isinstance(obj, pd.DataFrame):\n",
    "        converted_obj = pd.DataFrame()\n",
    "        if not features: features = obj.columns\n",
    "        #observe of columns \n",
    "        for col in features:\n",
    "            num_unique_values = len(obj[col].unique())\n",
    "            num_total_values = len(obj[col])\n",
    "            #if % of a unique feature less the min_value\n",
    "            if num_unique_values / num_total_values < min_value:\n",
    "                converted_obj.loc[:,col] = obj[col].astype('category')\n",
    "            else:\n",
    "                converted_obj.loc[:,col] = obj[col]\n",
    "        return converted_obj\n",
    "    #if Series\n",
    "    else:\n",
    "        num_unique_values = len(obj[col].unique())\n",
    "        num_total_values = len(obj[col])\n",
    "        #if % of a unique feature less the min_value\n",
    "        if num_unique_values / num_total_values < min_value:\n",
    "            return obj[col].astype('category')\n",
    "        else:\n",
    "            return obj[col]\n",
    "\n",
    "        \n",
    "        \n",
    "def as_dict(frame):\n",
    "    \"\"\"\n",
    "    Function transforms the frame to the dictionary\n",
    "    \n",
    "    input: pd.DataFrame\n",
    "    \n",
    "    return dictionary\n",
    "    \"\"\"\n",
    "    #process for transforming data into a dictionary\n",
    "    dtypes = frame.dtypes\n",
    "    dtypes_col = dtypes.index\n",
    "    dtypes_type = [i.name for i in dtypes.values]\n",
    "    column_types = dict(zip(dtypes_col, dtypes_type))\n",
    "    return {key:value for key,value in list(column_types.items())}\n",
    "\n",
    "\n",
    "\n",
    "def weight_reducer(frame, min_value=0.10, get_dict = None):\n",
    "    \"\"\"\n",
    "    Main function reduces a data frame weight\n",
    "    \n",
    "    input: pd.DataFrame\n",
    "    input: .0 =< min_value >= 1.\n",
    "    input: get_dict == bool\n",
    "    \n",
    "    return pd.DataFrame  \n",
    "    \"\"\"\n",
    "    #only if it is frame\n",
    "    if isinstance(frame, pd.DataFrame):\n",
    "        before = mem_usage(frame)\n",
    "        for dtype in set(frame.dtypes):\n",
    "            if 'float' in str(dtype):\n",
    "                cols = train_df[[col for col in train_df.columns if 'float' in str(train_df[col].dtypes)]].select_dtypes(include = [dtype]).columns\n",
    "                frame[cols] = frame[cols].select_dtypes(include = [dtype]). \\\n",
    "                              apply(pd.to_numeric, downcast='float')\n",
    "            if 'int' in str(dtype): \n",
    "                cols = train_df[[col for col in train_df.columns if 'int' in str(train_df[col].dtypes)]].select_dtypes(include = [dtype]).columns\n",
    "                frame[cols] = frame[cols].select_dtypes(include = [dtype]).\\\n",
    "                              apply(pd.to_numeric, downcast='unsigned')\n",
    "            frame= replace_cat(frame, min_value)\n",
    "        after = mem_usage(frame)\n",
    "        print('Columns - {}, early size - {}, replaced size - {}'.format(frame.shape[1], before, after))\n",
    "        if get_dict: frame = as_dict(frame)\n",
    "        return frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T11:39:35.818934Z",
     "start_time": "2019-04-19T11:39:35.807239Z"
    }
   },
   "outputs": [],
   "source": [
    "### Download your data set ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T11:44:38.949785Z",
     "start_time": "2019-04-19T11:44:38.860654Z"
    }
   },
   "outputs": [],
   "source": [
    "frame = train_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T11:49:32.121261Z",
     "start_time": "2019-04-19T11:49:31.611799Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31052 entries, 0 to 17526\n",
      "Columns: 1275 entries, SK_SUBS_ID to LIFT_ARPU\n",
      "dtypes: float64(1107), object(168)\n",
      "memory usage: 302.3+ MB\n"
     ]
    }
   ],
   "source": [
    "#check size of the data set\n",
    "frame.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T11:50:51.345845Z",
     "start_time": "2019-04-19T11:50:50.860058Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 31052 entries, 0 to 17526\n",
      "Columns: 1275 entries, SK_SUBS_ID to LIFT_ARPU\n",
      "dtypes: float64(1107), object(168)\n",
      "memory usage: 441.7 MB\n"
     ]
    }
   ],
   "source": [
    "#but! it't not true (302 MB, what does a plus mean?)\n",
    "#go deeper\n",
    "frame.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T11:55:31.871763Z",
     "start_time": "2019-04-19T11:53:21.446139Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns - 1275, early size - 441.70 MB, replaced size - 69.04 MB\n"
     ]
    }
   ],
   "source": [
    "#WOW! Difference is more the 130 MB\n",
    "#let's use reducing function\n",
    "reduced_frame = weight_reducer(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T11:57:15.305380Z",
     "start_time": "2019-04-19T11:57:15.303015Z"
    }
   },
   "outputs": [],
   "source": [
    "#Not bad, isn't it?\n",
    "#The function reduces our data set from 441 MB to 69 MB\n",
    "#Surprisingly!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T12:00:18.889374Z",
     "start_time": "2019-04-19T12:00:18.354422Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313.98 MB\n",
      "69.04 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>before</th>\n",
       "      <th>after</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>float32</th>\n",
       "      <td>1107.0</td>\n",
       "      <td>152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>object</th>\n",
       "      <td>168.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1121</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          before  after\n",
       "float32   1107.0    152\n",
       "object     168.0      2\n",
       "category     NaN   1121"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's check where data hid\n",
    "print(mem_usage(frame))\n",
    "print(mem_usage(reduced_frame))\n",
    "comparator = pd.concat([frame.dtypes, reduced_frame.dtypes],axis=1)\n",
    "comparator.columns = ['before','after']\n",
    "comparator.apply(pd.Series.value_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-19T12:19:51.867078Z",
     "start_time": "2019-04-19T12:19:22.300934Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns - 1275, early size - 313.98 MB, replaced size - 69.04 MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'DATE_KEY': 'category',\n",
       " 'END_DATE': 'category',\n",
       " 'END_WEEK_DATE': 'category',\n",
       " 'FILIAL_ID': 'category',\n",
       " 'SK_SUBS_ID': 'object',\n",
       " 'START_DATE': 'category',\n",
       " 'START_WEEK_DATE': 'category',\n",
       " 'TM_NONE_ALLOT': 'category',\n",
       " 'TM_NONE_CNT_3MNTH': 'category',\n",
       " 'TM_NONE_CNT_6MNTH': 'category'}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#unfortunately, it takes time ;(\n",
    "#How can we struggle with this probleb?\n",
    "#It would be better, if we was able to download reduced data\n",
    "#There is the way for downloading reduced data -> enable get_dict = True\n",
    "reduced_dict = weight_reducer(frame, get_dict = True)\n",
    "{k:reduced_dict[k] for k in frame.columns[:10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reduced_dict includes a dictionary, we use the dictionary during downloading a data set\n",
    "#due to DTYPE parametr we could download\n",
    "pd.read_csv(link, sep='\\t', encoding='utf-8', dtype=reduced_dict)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
